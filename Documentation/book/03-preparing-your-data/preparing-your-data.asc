== Preparing your data 

.Essential information about data preparation
*************************************************************
Our software calculates metrics over entire landscapes and along channels, and needs to measure distances and lengths. For this reason the data *must* be in a https://geonet.esri.com/thread/23160[projected reference system]. Because converting data types is nontrivial, we have opted to assume a certain reference system:

**All your raster data (i.e., your topographic data and subsidiary datasets) need to be in https://en.wikipedia.org/wiki/Universal_Transverse_Mercator_coordinate_system[UTM] coordinate system.**

We use [https://en.wikipedia.org/wiki/Universal_Transverse_Mercator_coordinate_system] since it is a global dataset. However you will need to look up the UTM zone of your data. We use http://www.dmap.co.uk/utmworld.htm[this map] to determine our UTM zone. 

**If you fail to convert to UTM these programs will probably crash!**
*************************************************************

=== Get some data

There are many sources of topogaphic data, which we will not repeat here, but if you are looking for an easy interface to get either lidar or SRTM data, we suggest http://www.opentopography.org/[opentopography]. This site is not jst for USA-based lidar but also has very nice interfaces for http://opentopo.sdsc.edu/lidar?format=sd[global data sets].

=== Use GDAL

When you download topographic data, it will come in all manner of formats, with all manner of coordinate systems. You need to convert the data into **ENVI bil** format and project it into UTM coordinates. You can do all this using http://www.gdal.org/[GDAL].

WARNING: *DO NOT* use ESRI bil format! Use *ENVI bil* format. They have similar names but the data format is different!!!

.Getting GDAL
***************************************************
* If you use our vagrant setup GDAL is already installed. This is appropriate for Windows and MacOS users.
* If you use Ubuntu, use: `sudo apt-get gdal-bin`
***************************************************

If you want to learn all about GDAL you can look at our book: http://lsdtopotools.github.io/LSDTT_book/#_gdal_2

However, all you really need to use is *gdalwarp*.

. Navigate to the folder where your data is sitting.
. Call *gdalwarp*:
+
[source,console]
----
$ gdalwarp -t_srs '+proj=utm +zone=19 +south +datum=WGS84' -of ENVI InputDEM.tif Output_DEM.bil
----
+ 
. The above all contains the essentials:
.. `-t_srs '+proj=utm +zone=19 +south +datum=WGS84'` says you want to project into UTM zone 19 south. Change the "south" and the "zone" accordingly. For example, if you want zone 44 north, use `-t_srs '+proj=utm +zone=44 +north +datum=WGS84'`.
.. `-of ENVI` means you want ENVI bil format. 
. If you want to control the spacing of the points, include:
+
[source,console]
----
$ gdalwarp -t_srs '+proj=utm +zone=19 +south +datum=WGS84' -tr 30 30 -r cubic -of ENVI InputDEM.tif Output_DEM.bil
----
+ 
. In this case the two extra flags are:
.. `-tr 30 30`: Resample to 30 metres in the x any y directions. Change the number for a different resolution. 
.. `-r cubic`: This is the resampling method. *DO NOT* use the default; it is nearest neighbour and will result in a striped DEM. 
. If you want to clip the DEM add `-te <x_min> <y_min> <x_max> <y_max>` where you put the maximum and minimum extents within the `<>` symbols. 

=== Stupid nodata

. Often you get messed up NoData. That is, you get some gigantic number for nodata or the nodata doesn't register on the projected DEM. You can attempt to fix this with gdal using the flag `dstnodata -9999`. However this doesn't always work. Luckily, we have programmed some code to try to remove weird numbers, so when you run the code (see the section <<Running the chi analysis>>) you turn the `remove_seas` switch to true and that should sort you out. 

. Sometimes you get holes in your data. This is annoying. We have code to deal with that, but for now I will just say that you should use the http://www.opentopography.org/[opentopography] data server to get SRTM data as it is seamless. Note that for chi analysis, 30 metre resolution data is probably sufficient: see http://www.earth-surf-dynam.net/4/627/2016/[Grieve et al, 2016] and http://www.earth-surf-dynam.net/5/211/2017/[Purinton and Bookhagen, 2017].





